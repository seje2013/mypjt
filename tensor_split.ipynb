{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "03ec7d960ce6c96cf44bd2e5d6a63ff4a5f3dfaf8ddc2669fd95e778e8e29ead"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.load('./input')\n",
    "weight = torch.load('./weight')\n",
    "input = torch.randint_like(input,16)\n",
    "weight = torch.randint_like(weight,16)\n",
    "output = F.conv2d(input, weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\ntime: 2.6888532638549805\n"
     ]
    }
   ],
   "source": [
    "lsb_weight = torch.fmod(weight, 4)\n",
    "msb_weight = torch.fmod((weight-lsb_weight)/4,4)\n",
    "split_weight = torch.cat((msb_weight, lsb_weight))\n",
    "start_time = time.time()\n",
    "for i in range(2000):\n",
    "    split_output = F.conv2d(input,split_weight)\n",
    "    split_output = (split_output[:,0:64,:,:]<<2) + split_output[:,64:128:,:,]\n",
    "print(torch.equal(split_output,output))\n",
    "end_time = time.time()\n",
    "print(f'time: {end_time-start_time}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\ntime: 4.42852783203125\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(2000):\n",
    "    weight_copy = weight.clone()\n",
    "    split_output = torch.zeros_like(output)\n",
    "    for i in range(2):\n",
    "        split_weight = torch.fmod(weight_copy, 4)\n",
    "        weight_copy = (weight_copy-split_weight)/4\n",
    "        output_temp = F.conv2d(input, split_weight)\n",
    "        split_output += output_temp <<(i*2)\n",
    "print(torch.equal(split_output,output))\n",
    "end_time = time.time()\n",
    "print(f'time: {end_time-start_time}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range (int(bitWeight/self.cellBit)):\n",
    "remainder = torch.fmod(X_decimal, cellRange)*mask\n",
    "# retention\n",
    "remainder = wage_quantizer.Retention(remainder,self.t,self.v,self.detect,self.target)\n",
    "variation = np.random.normal(0, self.vari, list(weight.size())).astype(np.float32)\n",
    "X_decimal = torch.round((X_decimal-remainder)/cellRange)*mask\n",
    "# Now also consider weight has on/off ratio effects\n",
    "# Here remainder is the weight mapped to Hardware, so we introduce on/off ratio in this value\n",
    "# the range of remainder is [0, cellRange-1], we truncate it to [lower, upper]\n",
    "remainderQ = (upper-lower)*(remainder-0)+(cellRange-1)*lower   # weight cannot map to 0, but to Gmin\n",
    "remainderQ = remainderQ + remainderQ*torch.from_numpy(variation).cuda()\n",
    "outputPartial= F.conv2d(inputB, remainderQ*mask, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "outputDummyPartial= F.conv2d(inputB, dummyP*mask, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "# Add ADC quanization effects here !!!\n",
    "outputPartialQ = wage_quantizer.LinearQuantizeOut(outputPartial, self.ADCprecision)\n",
    "outputDummyPartialQ = wage_quantizer.LinearQuantizeOut(outputDummyPartial, self.ADCprecision)\n",
    "scaler = cellRange**k\n",
    "outputP = outputP + outputPartialQ*scaler*2/(1-1/onoffratio)\n",
    "outputD = outputD + outputDummyPartialQ*scaler*2/(1-1/onoffratio)"
   ]
  }
 ]
}